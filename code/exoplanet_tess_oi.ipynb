{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is in progress and not meant to be a showpiece\n",
    "I will update this notebook as I go, and will remove this notice from the top when it is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Exoplanets using the TESS Objects of Interest Data Set\n",
    "***Matt Paterson***<br>\n",
    "***Machine Learning Engineer***<br>\n",
    "***Santa Cruz, California***<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about the Data**<br>\n",
    "This data set is downloaded from the Cal Tech NASA Exoplanet Archive found <a href='https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=TOI'>here</a> and was downloaded on 2021-03-06 for the purpose of creating this instructional notebook.\n",
    "\n",
    "**Note about the Spacecraft**<br>\n",
    "TESS was launched by NASA in 2018 aboard a SpaceX rocket and completed its initial mission in July of 2020, poitively identifying 66 planets and recording over 2100 objects of interest. You can learn more about TESS <a href='https://exoplanets.nasa.gov/tess/'>here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science Problem\n",
    "Can we use data from over 2000 observations made by the Transiting Exoplanet Survey Satellite (TESS) to positively identify more exoplanets in the sky using Machine Learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary python libraries\n",
    "In this notebook we will use python exclusively and in order to build our models, we'll utilize scikit-learn's libraries. This particular notebook will focus on the Logistic Regression model only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.metrics         import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import your data\n",
    "The data that we'll be using is already downloaded from CalTech/NASA, cleaned up a little for use here, and saved in a folder called 'data'. That 'data' folder lives in the same directory as a folder called 'code' where this notebook lives.\n",
    "\n",
    "In order to import the data set, you'll have to provide the pandas function with a full datapath to find your csv file. You can choose to do this using the absolute path, which is recommended for production code, but for ease in this situation, you can go ahead and use the relative path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/'\n",
    "filename = 'tess_oi.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you import the data set into a pandas DataFrame, go ahead and set the index column to 'rowid' using an argument in the pandas function. Then display 5 rows of data in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toi</th>\n",
       "      <th>toipfx</th>\n",
       "      <th>tid</th>\n",
       "      <th>ctoi_alias</th>\n",
       "      <th>pl_pnum</th>\n",
       "      <th>tfopwg_disp</th>\n",
       "      <th>rastr</th>\n",
       "      <th>ra</th>\n",
       "      <th>raerr1</th>\n",
       "      <th>raerr2</th>\n",
       "      <th>...</th>\n",
       "      <th>st_loggerr2</th>\n",
       "      <th>st_logglim</th>\n",
       "      <th>st_loggsymerr</th>\n",
       "      <th>st_rad</th>\n",
       "      <th>st_raderr1</th>\n",
       "      <th>st_raderr2</th>\n",
       "      <th>st_radlim</th>\n",
       "      <th>st_radsymerr</th>\n",
       "      <th>toi_created</th>\n",
       "      <th>rowupdate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rowid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1446.01</td>\n",
       "      <td>1446</td>\n",
       "      <td>294471966</td>\n",
       "      <td>294471966.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>20h08m00.35s</td>\n",
       "      <td>302.001457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076594</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830310</td>\n",
       "      <td>0.039874</td>\n",
       "      <td>-0.039874</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11/14/2019 17:07</td>\n",
       "      <td>10/30/2020 1:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1090.01</td>\n",
       "      <td>1090</td>\n",
       "      <td>361034196</td>\n",
       "      <td>361034196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "      <td>16h08m03.92s</td>\n",
       "      <td>242.016315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.610000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8/6/2019 19:30</td>\n",
       "      <td>12/17/2019 10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>2025.01</td>\n",
       "      <td>2025</td>\n",
       "      <td>394050135</td>\n",
       "      <td>394050135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>18h51m10.86s</td>\n",
       "      <td>282.795256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6/19/2020 7:20</td>\n",
       "      <td>11/17/2020 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1572.01</td>\n",
       "      <td>1572</td>\n",
       "      <td>292321872</td>\n",
       "      <td>292321872.0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP</td>\n",
       "      <td>02h07m36.53s</td>\n",
       "      <td>31.902189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12/19/2019 20:58</td>\n",
       "      <td>3/4/2020 12:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1245.01</td>\n",
       "      <td>1245</td>\n",
       "      <td>229781583</td>\n",
       "      <td>229781583.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC</td>\n",
       "      <td>18h54m08.53s</td>\n",
       "      <td>283.535530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008825</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524555</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>-0.015499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10/17/2019 0:30</td>\n",
       "      <td>10/30/2020 1:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           toi  toipfx        tid   ctoi_alias  pl_pnum tfopwg_disp  \\\n",
       "rowid                                                                 \n",
       "517    1446.01    1446  294471966  294471966.0        1          PC   \n",
       "101    1090.01    1090  361034196  361034196.0        1          FP   \n",
       "1185   2025.01    2025  394050135  394050135.0        1          PC   \n",
       "660    1572.01    1572  292321872  292321872.0        1          FP   \n",
       "280    1245.01    1245  229781583  229781583.0        1          PC   \n",
       "\n",
       "              rastr          ra  raerr1  raerr2  ... st_loggerr2  st_logglim  \\\n",
       "rowid                                            ...                           \n",
       "517    20h08m00.35s  302.001457     NaN     NaN  ...   -0.076594           0   \n",
       "101    16h08m03.92s  242.016315     NaN     NaN  ...   -0.610000           0   \n",
       "1185   18h51m10.86s  282.795256     NaN     NaN  ...   -0.080000           0   \n",
       "660    02h07m36.53s   31.902189     NaN     NaN  ...   -0.090000           0   \n",
       "280    18h54m08.53s  283.535530     NaN     NaN  ...   -0.008825           0   \n",
       "\n",
       "       st_loggsymerr    st_rad  st_raderr1  st_raderr2  st_radlim  \\\n",
       "rowid                                                               \n",
       "517                1  0.830310    0.039874   -0.039874          0   \n",
       "101                1  2.950000    0.160000   -0.160000          0   \n",
       "1185               1  1.480000    0.070000   -0.070000          0   \n",
       "660                1  2.520000    0.170000   -0.170000          0   \n",
       "280                1  0.524555    0.015499   -0.015499          0   \n",
       "\n",
       "       st_radsymerr       toi_created         rowupdate  \n",
       "rowid                                                    \n",
       "517               1  11/14/2019 17:07   10/30/2020 1:59  \n",
       "101               1    8/6/2019 19:30  12/17/2019 10:00  \n",
       "1185              1    6/19/2020 7:20  11/17/2020 12:00  \n",
       "660               1  12/19/2019 20:58    3/4/2020 12:58  \n",
       "280               1   10/17/2019 0:30   10/30/2020 1:59  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(datapath + filename, index_col='rowid')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns of data do you have in this data set? How many null values do you have in each column? Are the data types in the table logical and ready for modeling? Why or why not? What are some different python or pandas or matplotlib functions that you can use to inspect this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2542, 86)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2542 entries, 1 to 2542\n",
      "Data columns (total 86 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   toi                2542 non-null   float64\n",
      " 1   toipfx             2542 non-null   int64  \n",
      " 2   tid                2542 non-null   int64  \n",
      " 3   ctoi_alias         2542 non-null   float64\n",
      " 4   pl_pnum            2542 non-null   int64  \n",
      " 5   tfopwg_disp        2535 non-null   object \n",
      " 6   rastr              2542 non-null   object \n",
      " 7   ra                 2542 non-null   float64\n",
      " 8   raerr1             0 non-null      float64\n",
      " 9   raerr2             0 non-null      float64\n",
      " 10  decstr             2542 non-null   object \n",
      " 11  dec                2542 non-null   float64\n",
      " 12  decerr1            0 non-null      float64\n",
      " 13  decerr2            0 non-null      float64\n",
      " 14  st_pmra            2526 non-null   float64\n",
      " 15  st_pmraerr1        2526 non-null   float64\n",
      " 16  st_pmraerr2        2526 non-null   float64\n",
      " 17  st_pmralim         2526 non-null   float64\n",
      " 18  st_pmrasymerr      2526 non-null   float64\n",
      " 19  st_pmdec           2526 non-null   float64\n",
      " 20  st_pmdecerr1       2526 non-null   float64\n",
      " 21  st_pmdecerr2       2526 non-null   float64\n",
      " 22  st_pmdeclim        2526 non-null   float64\n",
      " 23  st_pmdecsymerr     2526 non-null   float64\n",
      " 24  pl_tranmid         2542 non-null   float64\n",
      " 25  pl_tranmiderr1     2521 non-null   float64\n",
      " 26  pl_tranmiderr2     2521 non-null   float64\n",
      " 27  pl_tranmidlim      2542 non-null   int64  \n",
      " 28  pl_tranmidsymerr   2542 non-null   int64  \n",
      " 29  pl_orbper          2463 non-null   float64\n",
      " 30  pl_orbpererr1      2426 non-null   float64\n",
      " 31  pl_orbpererr2      2426 non-null   float64\n",
      " 32  pl_orbperlim       2542 non-null   int64  \n",
      " 33  pl_orbpersymerr    2542 non-null   int64  \n",
      " 34  pl_trandurh        2542 non-null   float64\n",
      " 35  pl_trandurherr1    2535 non-null   float64\n",
      " 36  pl_trandurherr2    2535 non-null   float64\n",
      " 37  pl_trandurhlim     2542 non-null   int64  \n",
      " 38  pl_trandurhsymerr  2542 non-null   int64  \n",
      " 39  pl_trandep         2542 non-null   float64\n",
      " 40  pl_trandeperr1     2528 non-null   float64\n",
      " 41  pl_trandeperr2     2528 non-null   float64\n",
      " 42  pl_trandeplim      2542 non-null   int64  \n",
      " 43  pl_trandepsymerr   2542 non-null   int64  \n",
      " 44  pl_rade            2410 non-null   float64\n",
      " 45  pl_radeerr1        2280 non-null   float64\n",
      " 46  pl_radeerr2        2280 non-null   float64\n",
      " 47  pl_radelim         2542 non-null   int64  \n",
      " 48  pl_radesymerr      2542 non-null   int64  \n",
      " 49  pl_insol           2411 non-null   float64\n",
      " 50  pl_insolerr1       0 non-null      float64\n",
      " 51  pl_insolerr2       0 non-null      float64\n",
      " 52  pl_insollim        0 non-null      float64\n",
      " 53  pl_insolsymerr     0 non-null      float64\n",
      " 54  pl_eqt             2378 non-null   float64\n",
      " 55  pl_eqterr1         0 non-null      float64\n",
      " 56  pl_eqterr2         0 non-null      float64\n",
      " 57  pl_eqtlim          0 non-null      float64\n",
      " 58  pl_eqtsymerr       0 non-null      float64\n",
      " 59  st_tmag            2542 non-null   float64\n",
      " 60  st_tmagerr1        2542 non-null   float64\n",
      " 61  st_tmagerr2        2542 non-null   float64\n",
      " 62  st_tmaglim         2542 non-null   int64  \n",
      " 63  st_tmagsymerr      2542 non-null   int64  \n",
      " 64  st_dist            2492 non-null   float64\n",
      " 65  st_disterr1        2373 non-null   float64\n",
      " 66  st_disterr2        2373 non-null   float64\n",
      " 67  st_distlim         2542 non-null   int64  \n",
      " 68  st_distsymerr      2542 non-null   int64  \n",
      " 69  st_teff            2506 non-null   float64\n",
      " 70  st_tefferr1        2315 non-null   float64\n",
      " 71  st_tefferr2        2315 non-null   float64\n",
      " 72  st_tefflim         2542 non-null   int64  \n",
      " 73  st_teffsymerr      2542 non-null   int64  \n",
      " 74  st_logg            2297 non-null   float64\n",
      " 75  st_loggerr1        2009 non-null   float64\n",
      " 76  st_loggerr2        2009 non-null   float64\n",
      " 77  st_logglim         2542 non-null   int64  \n",
      " 78  st_loggsymerr      2542 non-null   int64  \n",
      " 79  st_rad             2409 non-null   float64\n",
      " 80  st_raderr1         2139 non-null   float64\n",
      " 81  st_raderr2         2139 non-null   float64\n",
      " 82  st_radlim          2542 non-null   int64  \n",
      " 83  st_radsymerr       2542 non-null   int64  \n",
      " 84  toi_created        2542 non-null   object \n",
      " 85  rowupdate          2542 non-null   object \n",
      "dtypes: float64(58), int64(23), object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toi               0\n",
       "toipfx            0\n",
       "tid               0\n",
       "ctoi_alias        0\n",
       "pl_pnum           0\n",
       "               ... \n",
       "st_raderr2      403\n",
       "st_radlim         0\n",
       "st_radsymerr      0\n",
       "toi_created       0\n",
       "rowupdate         0\n",
       "Length: 86, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick and dirty data cleaning\n",
    "With any dataset, you'll want to spend lots of time looking at each and every column of data and learning what each is and how it relates to the other columns. You'll employ correlation matrices, scatterplots, and bar charts to see patterns. You'll have to impute missing data and decide if some data can be imputed at all. You'll have to engineer data columns and aggregate data columns and convert columns to different units of measurement. \n",
    "\n",
    "This particular notebook is intended to help you learn how to use the Logistic Regression Classification Model, so rather than spend all of our time on the data (a typical Data Scientist spends most of their time acquiring, cleaning, and maintaining their data), we're going to make what I like to call the 'Quick and Dirty Model' by dropping all columns with null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop all null values\n",
    "Use a pandas method to drop all of the columns in your table that contain null values, and save this new dataframe to a variable called 'tess', and then print the number of rows and columns that the new 'tess' DataFrame contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2542, 37)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess = df.dropna(axis=1)\n",
    "tess.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add back our target column\n",
    "One of the columns that we dropped is actually VERY important to our model. df['tfopwg_disp'] is actually going to be our TARGET column, or the column that we're going to use for classification.\n",
    "\n",
    "Use pd.merge() to add that column back on to our table, minding the index so that we don't switch anything around and completely break our model before we build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess = pd.merge(tess, df['tfopwg_disp'], how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2542, 38)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of your new columns are non-numeric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toi                  float64\n",
       "toipfx                 int64\n",
       "tid                    int64\n",
       "ctoi_alias           float64\n",
       "pl_pnum                int64\n",
       "rastr                 object\n",
       "ra                   float64\n",
       "decstr                object\n",
       "dec                  float64\n",
       "pl_tranmid           float64\n",
       "pl_tranmidlim          int64\n",
       "pl_tranmidsymerr       int64\n",
       "pl_orbperlim           int64\n",
       "pl_orbpersymerr        int64\n",
       "pl_trandurh          float64\n",
       "pl_trandurhlim         int64\n",
       "pl_trandurhsymerr      int64\n",
       "pl_trandep           float64\n",
       "pl_trandeplim          int64\n",
       "pl_trandepsymerr       int64\n",
       "pl_radelim             int64\n",
       "pl_radesymerr          int64\n",
       "st_tmag              float64\n",
       "st_tmagerr1          float64\n",
       "st_tmagerr2          float64\n",
       "st_tmaglim             int64\n",
       "st_tmagsymerr          int64\n",
       "st_distlim             int64\n",
       "st_distsymerr          int64\n",
       "st_tefflim             int64\n",
       "st_teffsymerr          int64\n",
       "st_logglim             int64\n",
       "st_loggsymerr          int64\n",
       "st_radlim              int64\n",
       "st_radsymerr           int64\n",
       "toi_created           object\n",
       "rowupdate             object\n",
       "tfopwg_disp           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tess.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the DataFrame's dtypes attribute returns a pandas Series, list-like object, the values of which are all strings displaying the datatype of each column in your DataFrame. Can you figure out a way to display the names of just the columns that are non-numeric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toi', 'toipfx', 'tid', 'ctoi_alias', 'pl_pnum', 'rastr', 'ra',\n",
       "       'decstr', 'dec', 'pl_tranmid', 'pl_tranmidlim', 'pl_tranmidsymerr',\n",
       "       'pl_orbperlim', 'pl_orbpersymerr', 'pl_trandurh', 'pl_trandurhlim',\n",
       "       'pl_trandurhsymerr', 'pl_trandep', 'pl_trandeplim', 'pl_trandepsymerr',\n",
       "       'pl_radelim', 'pl_radesymerr', 'st_tmag', 'st_tmagerr1', 'st_tmagerr2',\n",
       "       'st_tmaglim', 'st_tmagsymerr', 'st_distlim', 'st_distsymerr',\n",
       "       'st_tefflim', 'st_teffsymerr', 'st_logglim', 'st_loggsymerr',\n",
       "       'st_radlim', 'st_radsymerr', 'toi_created', 'rowupdate', 'tfopwg_disp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HINT: You can see the index of each row of a pandas Series in the\n",
    "# same way that you list the index of each row in a pandas DataFrame\n",
    "tess.dtypes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a short-cut, you can always just manually copy/paste the non-numeric column names, but that's not really a shortcut option when you have more than four non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rastr\n",
      "decstr\n",
      "toi_created\n",
      "rowupdate\n",
      "tfopwg_disp\n"
     ]
    }
   ],
   "source": [
    "#create an empty dictionary for your dtypes\n",
    "dtype_dict = {}\n",
    "\n",
    "#iterate through the Series of tess.dtypes and \n",
    "#create your dictionary using the tess.dtypes.index Series as keys\n",
    "for i in range(len(tess.dtypes)):\n",
    "    dtype_dict[tess.dtypes.index[i]] = tess.dtypes[i]\n",
    "\n",
    "for key in dtype_dict:\n",
    "    if dtype_dict[key] == 'object':\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "What are these non-numeric columns? Are they important to our model? If so, how can we make them into numeric columns? \n",
    "\n",
    "There is a data dictionary in the data folder where we got the data set, and it should be helpful here. For more detailed information you can follow the link to the data set above and click on the \"view documentation\" button to see what these are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide This block] The 'rastr' and 'decstr' are fields for the location of the objects in the sky relative to earth, also known as the Right Acension and Declination. These columns are actually duplicated in the data because the 'ra' and 'dec' columns convert these stellar addresses to decimal degrees, allowing us to use them in the model (or even to map the sky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rowid\n",
       "1666     2/3/2021 22:59\n",
       "111      9/5/2018 18:34\n",
       "1124    6/17/2020 17:40\n",
       "49      6/25/2019 15:58\n",
       "2227    4/30/2019 13:04\n",
       "Name: toi_created, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess['toi_created'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rowid\n",
       "310     12/18/2020 12:01\n",
       "702      9/11/2020 16:00\n",
       "344      9/23/2020 16:00\n",
       "580      2/19/2021 16:00\n",
       "2071     2/18/2021 16:00\n",
       "Name: rowupdate, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess['rowupdate'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide This block] The 'toi_created' and 'rowupdate' fields are both dates and times when there were updates to the data table, one being the original discovery of the object of interest and the other being the last time information was added to the table in that row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop these columns\n",
    "We want to keep the 'tfopwg_disp' column as this will be our target column for our model, but we can drop the other four columns. \n",
    "\n",
    "We can drop them using the pd.DataFrame.drop() method, and we can make that permanent by dropping them \"inplace\" as we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess.drop(columns=['rastr', 'decstr', 'toi_created', 'rowupdate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2542, 34)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we even predicting here?\n",
    "We want to know if the dataset itself can help point out likely planetary candidates. To do this, we want to see what objects have already been identified by the CalTech and NASA scientists, and then infer commonalities in the data using Logistic Regression to classify the unclassified data points.\n",
    "\n",
    "This means we'll want to convert the classifications that we have into a binary set of positive and negatively identified planets. Given the nature of our data set, there will be a third category of \"unclassified\" data, which is what we'll deploy our model on once it is trainied. Sounds easy, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This key explains the basic classifications:\n",
    " \tTESS Follow-up Observing Program Working Group (TFOPWG) Dispostion:\n",
    "\n",
    "- CP=confirmed planet\n",
    "- KP=known planet\n",
    "- FP=false positive\n",
    "- PC=planetary candidate \n",
    "\n",
    "# warning - this might confuse you\n",
    "\n",
    "The term \"False Positive\" will be used by us, Data Scientists and Machine Learning Engineers, to identify an observation that our model predicts should be a \"Positive\" but that the ground truth tells is was a \"Negative\". Since we **predicted** this to be \"Positive\" and we were wrong, this is known as a \"False Positive\".\n",
    "\n",
    "The TESS Objects of Interest table was/is built by Scientists who have a good reason to think that these objects are good candidates to be exoplanets. As such, if it turns out that through further investigation that one of these observations is not in fact an exoplanet, they classify that as a \"false positive\". We're going to convert that classification to a simple negative designation.\n",
    "\n",
    "For ease of understanding, we'll create a mapping function to convert our designations to either 1 for exoplanet, 0 for not-exoplanet, or 2 for 'unclassified'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PC     0.560552\n",
       "FP     0.181854\n",
       "KP     0.112426\n",
       "APC    0.076529\n",
       "CP     0.053254\n",
       "FA     0.015385\n",
       "Name: tfopwg_disp, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess.tfopwg_disp.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict that maps the classifications in TOI \n",
    "# to the classifications that we'll use for modeling\n",
    "\n",
    "class_map = {\n",
    "    'PC':2,\n",
    "    'FP':0,\n",
    "    'KP':1,\n",
    "    'APC':2,\n",
    "    'CP':1,\n",
    "    'FA':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess['target'] = tess['tfopwg_disp'].map(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know that there are null fields in the target column. Since we know that no other fields are null in our dataframe, we can use the pd.DataFrame.fillna() funciton to change those NaN values to 'unclassified', or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess = tess.fillna(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at our baseline model numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    0.638080\n",
       "0.0    0.196696\n",
       "1.0    0.165224\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our original data set, 63.8% of the data are unclassified, 19.7% of the data are negatively classified, and 16.5% are positively classified.\n",
    "\n",
    "To train the model, we'll split off the unclassified data so that we're only training on classified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.543478\n",
       "1.0    0.456522\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_model = tess[tess['target'] != 2]\n",
    "tess_model.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this baseline score of 54.3% is what our model has to beat. If our we guessed that every object we saw was a planet, we'd be wrong 54.3% of the time (and a converse hypothesis would result in that maximum rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "We'll want to do more feature engineering to our dataset, but before we do, let's put down a couple of baselines by which to measure our progress. To do that, we're going to first see the distribution of the classfications in our target column, and then we'll use train_test_split to break up our data set into a training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 34)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_model = tess_model.drop(columns='tfopwg_disp')\n",
    "tess_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your X matrix and y vector\n",
    "X = tess_model.drop(columns='target')\n",
    "y = tess_model['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Time!!\n",
    "Instantiate a Logistic Regression Model and print out your training, testing, and overall accuracy scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score :  0.5652173913043478\n",
      "Testing Accuracy Score  :  0.47282608695652173\n",
      "Overall Accuracy Score  :  0.5467391304347826\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('Training Accuracy Score : ', model.score(X_train, y_train))\n",
    "print('Testing Accuracy Score  : ', model.score(X_test, y_test))\n",
    "print('Overall Accuracy Score  : ', model.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did we do? \n",
    "Recall that our baseline model, or the basic split between our binary classification classes, was 54%. Was our Quick and Dirty model an improvement over our baseline? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide this] No it was not. Our model performed about the same as the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is our Model well-fit? Is it showing signs of bias? Is it overfit? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale our data\n",
    "Using Standard Scaler to scale our data, we can bring our data in to a more readable place where our model can be better trained on the data and less sensitive to differences in numeric scale or measure.\n",
    "\n",
    "To better understand StandardScaler, and to help you use it, it's a good idea to check out the documentation <a href='https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html'>here</a><br>\n",
    "Note: Some code in this section borrowed from Tim Book and Matt Brems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale our data.\n",
    "# Relabeling scaled data as \"Z\" is common.\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "# DO NOT use 'fit' on your test data\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_train shape is: (736, 33)\n",
      "y_train shape is: (736,)\n",
      "Z_test shape is: (184, 33)\n",
      "y_test shape is: (184,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Z_train shape is: {Z_train.shape}')\n",
    "print(f'y_train shape is: {y_train.shape}')\n",
    "print(f'Z_test shape is: {Z_test.shape}')\n",
    "print(f'y_test shape is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try running the scaled data through a new Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score :  0.7078804347826086\n",
      "Testing Accuracy Score  :  0.6195652173913043\n"
     ]
    }
   ],
   "source": [
    "model_1 = LogisticRegression()\n",
    "model_1.fit(Z_train, y_train)\n",
    "print('Training Accuracy Score : ', model_1.score(Z_train, y_train))\n",
    "print('Testing Accuracy Score  : ', model_1.score(Z_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holy Smokes!\n",
    "we just improved our accuracy by 50%! Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide this] It's because we scaled the data so that the model wouldn't be confused by the drastically different numerical scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the confusion matrix tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[411,  89],\n",
       "       [196, 224]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the X matrix into a Z matrix\n",
    "Z = sc.transform(X)\n",
    "\n",
    "# Show the predictions that the model makes on Z\n",
    "y_pred = model_1.predict(Z)\n",
    "\n",
    "# Evaluate the confusion matrix\n",
    "confusion_matrix(y_true=y, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the confusion matrix into a visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_confusion_matrix(model_1, Z, y, cmap='cividis')  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the Confusion Matrix tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide this] We have 224 true positives and 89 false positives. We have 411 true negatives and 196 false negatives. That means that we erroneously classified 196 exoplanets as 'not-exoplanets'. Think of all the vacations that will never happen to those undiscovered planets if we didn't realize they were there. It also means that we classified 89 objects as 'exoplanets' when they were actually 'not-exoplanets'. That's a lot of rocket fuel to take us to nowhwere..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the following values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity (explain and compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (explain and compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity (explain and compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate (explain and compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision (explain and compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is our model well-fit? Does it appear to show bias or over-fitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide this] It's overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kinds of things might we do to improve our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide this] We can go through each of the features and examine what each one is. Are the numbers Cardinal or Ordinal? Should we actually one-hot-encode any of those fields? Are columns such as 'ra' and 'dec' useful to our model? If this were an unsupervised clustering algorithm, 'ra' and 'dec' might be very useful. However in this case, since they are addresses rather than units of measure, they may or may not help the LogisticRegression model. That's just one example.\n",
    "\n",
    "[Hide this] We can also see if there is more data. As it stands, we're trying to train a model on less than 1,000 rows of data. That's not a lot of data. We'll have much better luck building a model with ten or a hundred times that amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we call CalTech and NASA and tell them that we figured out which objects on the TESS Objects of Interest data set are Exoplanets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hide this] No we should not. Our model only has a testing score of 62%, which while that is better than the  baseline, it is still not likely to be an improvement on the current solution being employed. We need to go through our data set and greatly improve our accuracy if we want to share our model with industry, clients, or superiors.\n",
    "\n",
    "[Hide this] In many cases, the data that we'll find or acquire in the real world are incomplete, unreliable, or not very good at helping us predict results. In some cases 62% is the best accuracy that you can hope for. However, if you don't try to investigate every column in your dataset, you won't know for sure if you have the best possible model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "This is it, the moment you've been waiting for...time to make predictions on the unclassfied data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
